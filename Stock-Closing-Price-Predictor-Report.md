# Stock Closing Price Predictor — Project Report

## Abstract
The Stock Closing Price Predictor is a focused, educational web application that forecasts the next trading day’s closing price using historical OHLCV data. It acquires market data through yfinance, cleans and aligns records, and transforms prior‑day observations into features for supervised learning. Two complementary regression models are implemented: an interpretable Linear Regression baseline and a more expressive Random Forest Regressor that captures nonlinear interactions. Evaluation follows time‑aware practice with chronological train/test splits to avoid lookahead leakage. The interface supports ticker selection, date range control, model comparison, and CSV export. Visualizations include price trends, volume, feature distributions, and actual‑versus‑predicted scatter plots with metrics, enabling transparent diagnostics and reliable, reproducible experimentation. It prioritizes clarity, defensible methodology, and measured expectations, demonstrating how simple features and disciplined validation produce meaningful baselines. While not investment advice, the tool helps learners and practitioners explore short‑horizon behavior efficiently. The pipeline emphasizes deterministic configurations, sensible defaults, and concise outputs that accelerate iteration and peer review. Integrated charts make residual structure visible, highlighting periods of instability or regime change. The Random Forest often improves upon linear fit without obscuring reasoning, while Linear Regression remains invaluable for interpretability and calibration. Together, they establish an accessible benchmark that invites extension with richer features, robust cross‑validation, uncertainty estimation, and systematic backtesting practices.

## Introduction
This project frames near‑term stock prediction as a supervised regression task grounded in accessible market data and testable assumptions. By restricting inputs to prior‑day OHLCV and enforcing chronological splits, it curbs information leakage and aligns evaluation with plausible deployment. Users interact through a streamlined interface for ticker selection, date boundaries, model choice, visualization, and CSV export. The design favors reproducibility, modest resource requirements, and transparent diagnostics suitable for coursework, prototypes, and exploratory analytics. Results are communicated through standard metrics and intuitive plots rather than opaque composite scores. It emphasizes clarity over complexity, demonstrating how disciplined preprocessing, baseline modeling, and careful validation provide dependable reference points for subsequent enhancements. The application illustrates end‑to‑end practice from data acquisition to evaluation while avoiding heavy infrastructure and proprietary sources. Learners can compare model behavior directly, examining trade‑offs between interpretability and flexibility under realistic constraints. Visual artifacts help reveal outliers, volatility clusters, and residual patterns that inform future feature engineering. Deterministic seeds and pinned versions improve repeatability across environments, encouraging reliable collaboration. The project ultimately serves as a compact foundation for robust time‑series workflows, showcasing good habits that generalize beyond finance into other domains where temporal dependence matters and unbiased evaluation is essential for credible insights and decisions. These principles guide iterative development and deployment.

## Contents
Contents summarize the structure and flow of this report, guiding readers from motivation to implementation and evaluation. After the abstract and introduction, the problem statement articulates scope and constraints. Project motivation explains pedagogical and practical goals. Objectives and scope define deliverables and boundaries. Project modules outline the pipeline components. The block diagram visualizes data flow. The literature review situates methods. Requirements specify software and hardware. Implementation describes the end‑to‑end procedure. Testing technologies present validation approaches. Future scope lists enhancements. The conclusion synthesizes insights. References direct readers to primary sources for replication and extension and deepen understanding across varied application contexts.

## List of Tables
This section describes the tables that support comprehension, reproducibility, and comparison across configurations. A software requirements table lists core libraries, versions, and notes about compatibility. A hardware guidance table outlines minimum resources for smooth execution. A metrics summary table reports MSE and R² for each model and data window, enabling quick assessment of performance. A data coverage table records tickers, periods, and missingness notes. A configuration table captures split ratios, random seeds, and feature selections. Together, these concise, curated tables help readers replicate results, evaluate trade‑offs, and maintain consistent environments across machines and collaborators while improving traceability over iterative changes.

## List of Figures
Figures communicate trends, relationships, and model behavior efficiently. A block diagram illustrates data flow from user inputs through retrieval, preprocessing, feature engineering, splitting, modeling, evaluation, and outputs. A price trend figure shows historical closing levels and contextualizes volatility. A volume figure highlights trading intensity. Distribution plots characterize feature dispersion and potential outliers. An actual‑versus‑predicted scatter, with a fitted line, indicates calibration and residual structure. Collectively, these visuals complement numerical metrics, enabling rapid interpretation, spotting instability or regime shifts, and guiding targeted improvements to features, validation design, and model selection under realistic constraints and resource considerations alike.

## Abbreviations
Abbreviations standardize terminology and reduce ambiguity throughout the report. OHLCV denotes Open, High, Low, Close, and Volume, the core inputs. MSE represents Mean Squared Error, measuring average squared prediction error, while R² denotes the proportion of variance explained by the model. LR refers to Linear Regression, an interpretable baseline, and RF to Random Forest Regressor, a nonlinear ensemble. UI indicates the user interface, and CSV represents comma‑separated values used for exporting predictions. These concise labels keep prose readable, help align code and documentation, and support efficient collaboration among contributors with diverse backgrounds and responsibilities across projects, reviews, and maintenance cycles.

## 2. Problem Statement
Predict the next trading day’s closing price for a chosen stock using only prior‑day OHLCV features within a transparent, reproducible workflow. Formulate the task as supervised regression, enforce chronological splitting to prevent lookahead, and provide interpretable metrics and visual diagnostics. The system must handle arbitrary valid tickers, configurable date ranges, and common data cleanliness issues. It should deliver fast, credible baselines using Linear Regression and Random Forest, enabling comparison under identical conditions. Outputs include metrics, charts, and a downloadable CSV of test predictions. The design should remain lightweight, clearly documented, and suitable for education and prototyping and stakeholder communication exercises.

## 3. Project Motivation
Educational and practical users need compact, defensible baselines that illustrate end‑to‑end time‑series modeling without heavy infrastructure. This project demonstrates disciplined preprocessing, feature construction, chronological evaluation, and side‑by‑side model comparison. By surfacing interpretable metrics and intuitive plots, it encourages critical reasoning over headline accuracy claims. The application supports rapid iteration for coursework and prototypes, while remaining extensible to stronger models and richer features. It also embeds good habits—deterministic seeds, version pinning, and clear documentation—that ease collaboration and review. Ultimately, the project lowers barriers to entry and provides a trustworthy foundation for experimentation, communication, and subsequent enhancement across educational and professional contexts.

## 4. Objectives and Scope
Objectives are to deliver a reliable, concise pipeline for next‑day close prediction, expose performance transparently, and keep interaction intuitive. Scope limits inputs to prior‑day OHLCV, single‑step forecasting, and baseline models suitable for learning and rapid analysis. The system reports MSE and R², presents visual diagnostics, and exports predictions to CSV. It avoids trading rules, cost modeling, or multi‑horizon strategies. Clear boundaries help focus experimentation on features, validation, and model improvements rather than deployment complexity. These constraints support reproducibility, comparability, and ethical use, ensuring the project remains educational, lightweight, and genuinely useful for iterative exploration and transparent performance communication to stakeholders.

## 5. Project Modules
The system is organized into coherent modules that promote clarity and maintainability. Data ingestion retrieves OHLCV via yfinance with ticker validation. Preprocessing cleans records, aligns trading days, and establishes a monotonic time index. Feature engineering constructs supervised pairs by shifting the close to t+1 and removing unlabeled rows. Modeling trains Linear Regression and Random Forest under consistent preprocessing. Evaluation computes MSE and R² and produces diagnostics. Visualization and UI render trends, comparisons, and outputs. Export utilities provide downloadable predictions for further analysis. This modular design enables incremental improvement while preserving reproducibility and separation of concerns through careful interfaces and tests.

## 6. Block Diagram
The block diagram clarifies the end‑to‑end flow from inputs to outputs, making dependencies explicit and onboarding faster. User selections trigger data acquisition from yfinance. Preprocessing aligns timestamps, handles missing values, and ensures consistent indexing. Feature engineering converts prior‑day OHLCV into predictors and shifts the close to form next‑day targets. A chronological split divides training and test sets to respect temporal order. Models train in parallel for comparison, and evaluation produces metrics and diagnostics. Visualizations summarize trends and calibration, while outputs include a forecast and CSV exports. This structure supports extension without destabilizing established behavior and encourages systematic, transparent engineering practices.

```mermaid
flowchart LR
    U[User Inputs: Ticker, Dates, Model] --> YF[yfinance: Fetch OHLCV]
    YF --> PP[Preprocess & Align Data]
    PP --> FE[Feature Engineering: X_t, y_{t+1}]
    FE --> SPLIT[Chronological Train/Test Split]
    SPLIT --> LR[Linear Regression]
    SPLIT --> RF[Random Forest]
    LR --> EVAL[Metrics: MSE, R²]
    RF --> EVAL
    EVAL --> VIS[Charts: Trends, Scatter]
    VIS --> PRED[Next-Day Forecast]
    EVAL --> CSV[Export Test Predictions]
```

## 7. Literature Review
Research on short‑horizon equity predictability shows limited linear structure but exploitable nonlinearities under certain conditions. Classical linear regression offers interpretability and calibration but struggles with interactions. Ensemble methods, including Random Forests, improve flexibility and reduce variance through averaging, though they require careful validation to avoid overfitting. Time‑series cross‑validation and walk‑forward testing address temporal dependence and non‑stationarity. Feature engineering using technical indicators and rolling statistics may improve performance but increases complexity and risk of leakage. Transparent metrics and diagnostic plots remain essential for credible assessment. The project adopts these lessons to balance rigor, clarity, and practicality in realistic financial data settings.

## 8. Requirements
Requirements emphasize minimal dependencies and portability. Python, pandas, numpy, scikit‑learn, and yfinance form the core stack, supplemented by a lightweight web framework for interactivity. Modest hardware suffices: multi‑core CPU, 4–8 GB RAM, and limited storage. Stable internet access is necessary for data retrieval; optional caching can reduce latency. Deterministic seeds, pinned package versions, and a documented environment file improve reproducibility. Optional plotting libraries enhance diagnostics. Containerization enables consistent execution across machines. Security practices include avoiding embedded secrets and respecting data provider terms. These choices enable quick setup, reliable results, and straightforward collaboration for education and prototyping with sustainable maintenance overhead.

## 9. Project Implementation
Implementation proceeds from data retrieval to export. The application fetches OHLCV for the specified ticker and dates, then cleans and aligns records. Feature engineering forms supervised examples by shifting the close to t+1 and discarding unlabeled rows. A chronological split partitions training and test sets. Linear Regression and Random Forest are trained using consistent preprocessing, then evaluated with MSE and R². Visualizations present trend lines and actual‑versus‑predicted scatter, revealing fit quality. The interface displays metrics and the next‑day forecast, and enables CSV downloads of test predictions. Deterministic seeds and pinned versions enhance repeatability and review during collaborative development and auditing.

## 10. Testing Technologies
Testing prioritizes temporal integrity, reproducibility, and clear baselines. Chronological train/test splits emulate deployment conditions and avoid lookahead. Deterministic seeds stabilize comparisons. Smoke tests verify data retrieval, preprocessing, and model training on representative tickers. Sanity checks compare models against a naive persistence baseline to contextualize gains. Metric tracking ensures MSE and R² remain within expected ranges. Visual diagnostics expose residual patterns and instability. Optional notebooks or scripts can batch evaluations across tickers and windows, revealing sensitivity to data selection. These practices create reliable feedback loops, enabling disciplined iteration and safeguarding credibility when presenting results to stakeholders and supporting long‑term quality assurance.

## 11. Future Scope
Future enhancements focus on features, models, validation, uncertainty, and operations. Feature expansion may include technical indicators, rolling statistics, calendar effects, sector indices, and macro signals. Model upgrades could add gradient boosting, regularized linear models, and thoughtfully tuned ensembles. Validation can adopt walk‑forward backtesting and time‑series cross‑validation with hyperparameter optimization. Uncertainty estimation via quantile regression or conformal prediction provides calibrated intervals. Operational improvements include caching, monitoring, data validation, drift detection, containerization, and CI for tests and linting. UX additions may enable multi‑ticker comparison, ensembles, and scenario analysis, while preserving transparency and reproducibility throughout the workflow and encouraging responsible deployment over hype.

## 12. Conclusion
This project delivers a transparent, reproducible baseline for next‑day stock closing price prediction using prior‑day OHLCV. By pairing interpretable Linear Regression with a flexible Random Forest and enforcing chronological evaluation, it demonstrates sound practices for short‑horizon modeling. The interface streamlines analysis through metrics, diagnostics, and exports, supporting efficient iteration and informed discussion. Although not investment advice, the system provides credible reference points for learning and prototyping. Its modular architecture, deterministic configurations, and clear documentation facilitate extension into richer features, stronger models, robust validation, and operational hardening, while preserving the clarity and discipline that underpin trustworthy results in varied data conditions.

## 13. References
References include foundational libraries and representative research on financial forecasting and time‑series evaluation. Key software sources are the documentation for yfinance, pandas, numpy, scikit‑learn, and the chosen web framework. Methodological guidance spans temporal cross‑validation, walk‑forward backtesting, leakage prevention, and evaluation best practices. Readers should consult authoritative texts and peer‑reviewed articles for deeper treatment of predictive modeling under non‑stationarity, ensemble learning, and uncertainty quantification. Practical deployment knowledge can be drawn from resources on reproducible environments, containerization, and CI. Together, these references enable replication, extension, and responsible communication of results across diverse contexts and collaborative settings within ethical and methodological guardrails universally.
